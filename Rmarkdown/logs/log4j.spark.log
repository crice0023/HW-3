24/04/10 08:09:10.845 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/conf/hive-site.xml
24/04/10 08:09:11.248 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.1
24/04/10 08:09:11.249 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 10, 10.0, amd64
24/04/10 08:09:11.250 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_401
24/04/10 08:09:11.776 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/10 08:09:12.084 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/10 08:09:12.230 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:09:12.231 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/10 08:09:12.232 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:09:12.233 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/10 08:09:12.278 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/10 08:09:12.304 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/10 08:09:12.306 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/10 08:09:12.403 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: ricecakes
24/04/10 08:09:12.403 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: ricecakes
24/04/10 08:09:12.404 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/10 08:09:12.405 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/10 08:09:12.406 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ricecakes; groups with view permissions: EMPTY; users with modify permissions: ricecakes; groups with modify permissions: EMPTY
24/04/10 08:09:12.572 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 61468.
24/04/10 08:09:12.603 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/10 08:09:12.666 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/10 08:09:12.719 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/10 08:09:12.720 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/10 08:09:12.724 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/10 08:09:13.225 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\blockmgr-48c086a0-38ca-4fbd-86c9-0f44f0b5f309
24/04/10 08:09:13.264 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/10 08:09:13.299 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/10 08:09:13.306 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/10 08:09:13.630 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
24/04/10 08:09:13.762 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/10 08:09:13.829 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/ricecakes/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:61468/jars/sparklyr-master-2.12.jar with timestamp 1712750951231
24/04/10 08:09:13.980 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
24/04/10 08:09:13.980 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 10, 10.0, amd64
24/04/10 08:09:13.980 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_401
24/04/10 08:09:13.996 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/10 08:09:13.996 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7960e5df for default.
24/04/10 08:09:14.030 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:61468/jars/sparklyr-master-2.12.jar with timestamp 1712750951231
24/04/10 08:09:14.119 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61468 after 37 ms (0 ms spent in bootstraps)
24/04/10 08:09:14.127 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:61468/jars/sparklyr-master-2.12.jar to C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\spark-3ee43c1b-9739-4a10-b23a-83f63ccd42b7\userFiles-33d6c2dd-ca3c-4e82-99fd-2f2aafeb586f\fetchFileTemp6744366320456699155.tmp
24/04/10 08:09:14.547 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local/spark-3ee43c1b-9739-4a10-b23a-83f63ccd42b7/userFiles-33d6c2dd-ca3c-4e82-99fd-2f2aafeb586f/sparklyr-master-2.12.jar to class loader default
24/04/10 08:09:14.573 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61496.
24/04/10 08:09:14.573 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:61496
24/04/10 08:09:14.575 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/10 08:09:14.578 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61496, None)
24/04/10 08:09:14.594 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61496 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 61496, None)
24/04/10 08:09:14.594 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61496, None)
24/04/10 08:09:14.594 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61496, None)
24/04/10 08:09:17.379 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/10 08:09:17.578 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive'.
24/04/10 08:09:33.854 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/10 08:09:33.855 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/10 08:24:44.895 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/conf/hive-site.xml
24/04/10 08:24:45.282 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.1
24/04/10 08:24:45.282 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 10, 10.0, amd64
24/04/10 08:24:45.282 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_401
24/04/10 08:24:45.318 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/10 08:24:45.500 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/10 08:24:45.565 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:24:45.566 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/10 08:24:45.567 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:24:45.568 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/10 08:24:45.619 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/10 08:24:45.645 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/10 08:24:45.646 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/10 08:24:45.748 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: ricecakes
24/04/10 08:24:45.748 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: ricecakes
24/04/10 08:24:45.748 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/10 08:24:45.748 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/10 08:24:45.748 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ricecakes; groups with view permissions: EMPTY; users with modify permissions: ricecakes; groups with modify permissions: EMPTY
24/04/10 08:24:45.959 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 62018.
24/04/10 08:24:46.012 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/10 08:24:46.089 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/10 08:24:46.142 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/10 08:24:46.143 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/10 08:24:46.150 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/10 08:24:46.198 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\blockmgr-80cf1af4-0c1a-4bd6-9cb0-62b99c701e38
24/04/10 08:24:46.217 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/10 08:24:46.255 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/10 08:24:46.260 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/10 08:24:46.539 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
24/04/10 08:24:46.667 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/10 08:24:46.735 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/ricecakes/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:62018/jars/sparklyr-master-2.12.jar with timestamp 1712751885275
24/04/10 08:24:46.865 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
24/04/10 08:24:46.865 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 10, 10.0, amd64
24/04/10 08:24:46.865 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_401
24/04/10 08:24:46.882 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/10 08:24:46.884 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@62f6e96c for default.
24/04/10 08:24:46.909 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:62018/jars/sparklyr-master-2.12.jar with timestamp 1712751885275
24/04/10 08:24:47.015 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62018 after 62 ms (0 ms spent in bootstraps)
24/04/10 08:24:47.015 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:62018/jars/sparklyr-master-2.12.jar to C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\spark-ed563c57-b979-48e6-be38-417fea182c93\userFiles-83324c3c-fa0c-4b40-8cf3-178c59acdfb2\fetchFileTemp3695214071687036855.tmp
24/04/10 08:24:47.155 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local/spark-ed563c57-b979-48e6-be38-417fea182c93/userFiles-83324c3c-fa0c-4b40-8cf3-178c59acdfb2/sparklyr-master-2.12.jar to class loader default
24/04/10 08:24:47.180 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62046.
24/04/10 08:24:47.181 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:62046
24/04/10 08:24:47.184 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/10 08:24:47.199 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62046, None)
24/04/10 08:24:47.206 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62046 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 62046, None)
24/04/10 08:24:47.210 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62046, None)
24/04/10 08:24:47.213 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62046, None)
24/04/10 08:24:47.714 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/10 08:24:47.734 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive'.
24/04/10 08:25:01.297 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/10 08:25:02.882 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive
24/04/10 08:25:03.992 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/10 08:25:03.992 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/10 08:25:03.992 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/10 08:25:04.392 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/10 08:25:05.232 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/10 08:25:05.277 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/10 08:25:09.549 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/10 08:25:14.537 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/10 08:25:14.540 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/10 08:25:14.862 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/10 08:25:14.862 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.86.223
24/04/10 08:25:15.033 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/10 08:25:15.388 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/10 08:25:15.388 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/10 08:25:15.630 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/10 08:25:16.490 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:25:16.506 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:25:16.640 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/10 08:25:16.640 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/10 08:25:16.640 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/10 08:25:16.640 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:25:16.640 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:25:16.640 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:25:16.640 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:25:16.656 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/10 08:25:16.656 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/10 08:25:20.535 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 1051.4084 ms
24/04/10 08:25:21.042 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:25:21.068 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.025235 s
24/04/10 08:25:32.634 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.2871 ms
24/04/10 08:25:32.676 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:25:32.756 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:25:32.757 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/10 08:25:32.757 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:25:32.759 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:25:32.764 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
24/04/10 08:25:33.064 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.1 KiB, free 912.3 MiB)
24/04/10 08:25:33.578 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
24/04/10 08:25:33.581 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62046 (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:25:33.584 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
24/04/10 08:25:33.830 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:25:33.853 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/10 08:25:33.986 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8003 bytes) 
24/04/10 08:25:34.066 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/10 08:25:34.651 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 82.5832 ms
24/04/10 08:25:35.333 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
24/04/10 08:25:35.420 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1466 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:25:35.420 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/10 08:25:35.448 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 2.648 s
24/04/10 08:25:35.456 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:25:35.457 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/10 08:25:35.458 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 2.775522 s
24/04/10 08:25:35.699 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 122.317 ms
24/04/10 08:25:36.465 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:25:36.465 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:25:36.465 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/10 08:25:36.465 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:25:36.465 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:25:36.465 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
24/04/10 08:25:36.481 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.1 KiB, free 912.3 MiB)
24/04/10 08:25:36.484 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
24/04/10 08:25:36.485 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62046 (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:25:36.486 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
24/04/10 08:25:36.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:25:36.486 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/10 08:25:36.486 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8003 bytes) 
24/04/10 08:25:36.486 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/10 08:25:36.502 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1370 bytes result sent to driver
24/04/10 08:25:36.502 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 16 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:25:36.502 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/10 08:25:36.502 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.037 s
24/04/10 08:25:36.502 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:25:36.502 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/10 08:25:36.502 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.043521 s
24/04/10 08:25:38.000 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 46.9909 ms
24/04/10 08:25:38.048 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:25:38.050 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:25:38.050 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/10 08:25:38.050 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:25:38.050 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:25:38.050 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/10 08:25:38.050 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.3 KiB, free 912.3 MiB)
24/04/10 08:25:38.050 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 912.3 MiB)
24/04/10 08:25:38.065 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62046 (size: 4.7 KiB, free: 912.3 MiB)
24/04/10 08:25:38.065 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
24/04/10 08:25:38.065 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:25:38.065 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/10 08:25:38.802 dispatcher-event-loop-1 WARN TaskSetManager: Stage 2 contains a task of very large size (60001 KiB). The maximum recommended task size is 1000 KiB.
24/04/10 08:25:38.804 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 61441898 bytes) 
24/04/10 08:25:38.806 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/10 08:25:39.230 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 55.8054 ms
24/04/10 08:25:39.535 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 939235 bytes result sent to driver
24/04/10 08:25:39.541 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1476 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:25:39.542 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1.492 s
24/04/10 08:25:39.542 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:25:39.541 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/10 08:25:39.543 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/10 08:25:39.544 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1.494832 s
24/04/10 08:25:39.667 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 35.1771 ms
24/04/10 08:26:58.061 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:62046 in memory (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:26:58.061 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:62046 in memory (size: 4.7 KiB, free: 912.3 MiB)
24/04/10 08:27:20.833 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 204.626 ms
24/04/10 08:27:21.468 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 12 (collect at utils.scala:26) as input to shuffle 0
24/04/10 08:27:21.513 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:27:21.513 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collect at utils.scala:26)
24/04/10 08:27:21.514 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:27:21.515 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:27:21.517 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[12] at collect at utils.scala:26), which has no missing parents
24/04/10 08:27:21.537 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 50.9 KiB, free 912.2 MiB)
24/04/10 08:27:21.586 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 912.2 MiB)
24/04/10 08:27:21.587 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62046 (size: 21.0 KiB, free: 912.3 MiB)
24/04/10 08:27:21.587 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
24/04/10 08:27:21.590 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[12] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:27:21.590 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/10 08:27:21.885 dispatcher-event-loop-0 WARN TaskSetManager: Stage 3 contains a task of very large size (60001 KiB). The maximum recommended task size is 1000 KiB.
24/04/10 08:27:21.885 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 61441887 bytes) 
24/04/10 08:27:21.885 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/10 08:27:22.203 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 104.6644 ms
24/04/10 08:27:22.284 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 27.3048 ms
24/04/10 08:27:22.333 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 9.4465 ms
24/04/10 08:27:22.352 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 13.0712 ms
24/04/10 08:27:22.367 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 11.2759 ms
24/04/10 08:27:22.796 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2302 bytes result sent to driver
24/04/10 08:27:22.800 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1209 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:27:22.800 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/10 08:27:22.802 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:26) finished in 1.281 s
24/04/10 08:27:22.802 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/10 08:27:22.802 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/10 08:27:22.802 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/10 08:27:22.802 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/10 08:27:22.841 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
24/04/10 08:27:22.951 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
24/04/10 08:27:23.019 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 35.998 ms
24/04/10 08:27:23.102 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:27:23.117 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:27:23.117 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/10 08:27:23.117 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
24/04/10 08:27:23.117 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:27:23.117 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
24/04/10 08:27:23.133 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 54.3 KiB, free 912.2 MiB)
24/04/10 08:27:23.133 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 912.1 MiB)
24/04/10 08:27:23.133 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62046 (size: 22.6 KiB, free: 912.3 MiB)
24/04/10 08:27:23.133 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
24/04/10 08:27:23.133 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:27:23.133 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/10 08:27:23.168 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7795 bytes) 
24/04/10 08:27:23.169 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
24/04/10 08:27:23.252 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Getting 1 (204.4 KiB) non-empty blocks including 1 (204.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/10 08:27:23.252 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
24/04/10 08:27:23.302 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO CodeGenerator: Code generated in 37.0082 ms
24/04/10 08:27:23.416 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 195836 bytes result sent to driver
24/04/10 08:27:23.416 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 251 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:27:23.416 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/10 08:27:23.416 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.283 s
24/04/10 08:27:23.416 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:27:23.416 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/10 08:27:23.416 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.305810 s
24/04/10 08:27:23.447 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 20.6282 ms
24/04/10 08:33:22.051 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/conf/hive-site.xml
24/04/10 08:33:22.412 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.1
24/04/10 08:33:22.412 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 10, 10.0, amd64
24/04/10 08:33:22.412 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_401
24/04/10 08:33:22.444 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/10 08:33:22.615 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/10 08:33:22.662 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:33:22.662 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/10 08:33:22.662 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:33:22.662 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/10 08:33:22.693 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/10 08:33:22.725 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/10 08:33:22.725 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/10 08:33:22.818 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: ricecakes
24/04/10 08:33:22.818 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: ricecakes
24/04/10 08:33:22.818 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/10 08:33:22.818 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/10 08:33:22.818 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ricecakes; groups with view permissions: EMPTY; users with modify permissions: ricecakes; groups with modify permissions: EMPTY
24/04/10 08:33:22.990 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 62240.
24/04/10 08:33:23.022 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/10 08:33:23.084 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/10 08:33:23.115 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/10 08:33:23.115 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/10 08:33:23.131 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/10 08:33:23.162 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\blockmgr-329f5630-fdf3-4e06-9a98-299161c763e4
24/04/10 08:33:23.209 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/10 08:33:23.240 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/10 08:33:23.240 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/10 08:33:23.568 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
24/04/10 08:33:23.740 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/10 08:33:23.818 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/ricecakes/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:62240/jars/sparklyr-master-2.12.jar with timestamp 1712752402397
24/04/10 08:33:23.959 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
24/04/10 08:33:23.959 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 10, 10.0, amd64
24/04/10 08:33:23.959 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_401
24/04/10 08:33:23.975 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/10 08:33:23.975 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@13c107c8 for default.
24/04/10 08:33:24.006 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:62240/jars/sparklyr-master-2.12.jar with timestamp 1712752402397
24/04/10 08:33:24.084 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62240 after 33 ms (0 ms spent in bootstraps)
24/04/10 08:33:24.084 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:62240/jars/sparklyr-master-2.12.jar to C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\spark-720251aa-4278-45f6-9099-94acf54ea2dc\userFiles-741093aa-514b-4e0f-942f-64e7c558444f\fetchFileTemp8263601320822724793.tmp
24/04/10 08:33:24.334 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local/spark-720251aa-4278-45f6-9099-94acf54ea2dc/userFiles-741093aa-514b-4e0f-942f-64e7c558444f/sparklyr-master-2.12.jar to class loader default
24/04/10 08:33:24.350 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62268.
24/04/10 08:33:24.350 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:62268
24/04/10 08:33:24.350 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/10 08:33:24.365 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62268, None)
24/04/10 08:33:24.381 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62268 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 62268, None)
24/04/10 08:33:24.381 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62268, None)
24/04/10 08:33:24.381 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62268, None)
24/04/10 08:33:24.834 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/10 08:33:24.850 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive'.
24/04/10 08:33:30.587 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/10 08:33:31.074 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive
24/04/10 08:33:31.309 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/10 08:33:31.309 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/10 08:33:31.309 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/10 08:33:31.387 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/10 08:33:31.668 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/10 08:33:31.670 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/10 08:33:33.681 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/10 08:33:36.375 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/10 08:33:36.375 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/10 08:33:36.483 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/10 08:33:36.484 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.86.223
24/04/10 08:33:36.506 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/10 08:33:36.769 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/10 08:33:36.773 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/10 08:33:36.847 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/10 08:33:37.034 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:33:37.037 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:33:37.068 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/10 08:33:37.069 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/10 08:33:37.070 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/10 08:33:37.072 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:33:37.072 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:33:37.076 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:33:37.076 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:33:37.080 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/10 08:33:37.080 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/10 08:33:38.469 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 362.2583 ms
24/04/10 08:33:38.672 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:33:38.688 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.008953 s
24/04/10 08:33:47.820 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.9826 ms
24/04/10 08:33:47.852 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:33:47.876 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:33:47.877 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/10 08:33:47.878 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:33:47.880 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:33:47.885 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
24/04/10 08:33:47.982 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.1 KiB, free 912.3 MiB)
24/04/10 08:33:48.053 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
24/04/10 08:33:48.053 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62268 (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:33:48.070 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
24/04/10 08:33:48.094 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:33:48.096 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/10 08:33:48.182 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8003 bytes) 
24/04/10 08:33:48.569 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/10 08:33:49.081 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 28.1137 ms
24/04/10 08:33:49.121 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1499 bytes result sent to driver
24/04/10 08:33:49.138 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1001 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:33:49.141 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/10 08:33:49.152 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 1.247 s
24/04/10 08:33:49.159 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:33:49.159 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/10 08:33:49.161 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 1.308425 s
24/04/10 08:33:49.255 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 48.4361 ms
24/04/10 08:33:49.698 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:33:49.699 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:33:49.699 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/10 08:33:49.699 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:33:49.699 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:33:49.701 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
24/04/10 08:33:49.704 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.1 KiB, free 912.3 MiB)
24/04/10 08:33:49.706 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
24/04/10 08:33:49.707 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62268 (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:33:49.707 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
24/04/10 08:33:49.708 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:33:49.709 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/10 08:33:49.710 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8003 bytes) 
24/04/10 08:33:49.711 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/10 08:33:49.721 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1413 bytes result sent to driver
24/04/10 08:33:49.723 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 13 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:33:49.723 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/10 08:33:49.723 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.021 s
24/04/10 08:33:49.723 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:33:49.723 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/10 08:33:49.723 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.029604 s
24/04/10 08:33:50.472 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 40.0515 ms
24/04/10 08:33:50.517 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:33:50.519 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:33:50.519 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/10 08:33:50.519 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:33:50.519 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:33:50.521 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/10 08:33:50.525 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.2 KiB, free 912.3 MiB)
24/04/10 08:33:50.527 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 912.3 MiB)
24/04/10 08:33:50.529 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62268 (size: 4.7 KiB, free: 912.3 MiB)
24/04/10 08:33:50.530 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
24/04/10 08:33:50.531 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:33:50.531 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/10 08:33:51.178 dispatcher-event-loop-2 WARN TaskSetManager: Stage 2 contains a task of very large size (60001 KiB). The maximum recommended task size is 1000 KiB.
24/04/10 08:33:51.178 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 61441898 bytes) 
24/04/10 08:33:51.180 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/10 08:33:51.600 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:62268 in memory (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:33:51.688 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 29.5127 ms
24/04/10 08:33:51.952 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 939278 bytes result sent to driver
24/04/10 08:33:51.952 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1420 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:33:51.952 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1.430 s
24/04/10 08:33:51.952 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:33:51.952 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/10 08:33:51.952 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/10 08:33:51.952 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1.448463 s
24/04/10 08:33:52.088 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 34.6564 ms
24/04/10 08:35:01.036 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 115.2692 ms
24/04/10 08:35:01.180 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 12 (collect at utils.scala:26) as input to shuffle 0
24/04/10 08:35:01.181 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:35:01.181 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collect at utils.scala:26)
24/04/10 08:35:01.181 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:35:01.181 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:35:01.181 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[12] at collect at utils.scala:26), which has no missing parents
24/04/10 08:35:01.217 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 50.9 KiB, free 912.2 MiB)
24/04/10 08:35:01.331 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 912.2 MiB)
24/04/10 08:35:01.331 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62268 (size: 21.0 KiB, free: 912.3 MiB)
24/04/10 08:35:01.331 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
24/04/10 08:35:01.331 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[12] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:35:01.331 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/10 08:35:01.631 dispatcher-event-loop-0 WARN TaskSetManager: Stage 3 contains a task of very large size (60001 KiB). The maximum recommended task size is 1000 KiB.
24/04/10 08:35:01.631 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 61441887 bytes) 
24/04/10 08:35:01.648 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/10 08:35:01.878 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 85.2779 ms
24/04/10 08:35:01.922 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 27.9666 ms
24/04/10 08:35:01.975 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 13.1244 ms
24/04/10 08:35:01.997 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 15.5095 ms
24/04/10 08:35:02.031 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 11.8577 ms
24/04/10 08:35:02.303 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2302 bytes result sent to driver
24/04/10 08:35:02.305 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 974 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:35:02.306 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/10 08:35:02.308 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:26) finished in 1.112 s
24/04/10 08:35:02.309 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/10 08:35:02.309 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/10 08:35:02.310 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/10 08:35:02.310 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/10 08:35:02.346 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
24/04/10 08:35:02.376 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
24/04/10 08:35:02.437 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 39.6065 ms
24/04/10 08:35:02.492 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:35:02.494 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:35:02.495 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/10 08:35:02.495 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
24/04/10 08:35:02.495 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:35:02.497 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
24/04/10 08:35:02.516 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 54.3 KiB, free 912.1 MiB)
24/04/10 08:35:02.518 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 912.1 MiB)
24/04/10 08:35:02.520 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62268 (size: 22.6 KiB, free: 912.2 MiB)
24/04/10 08:35:02.521 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
24/04/10 08:35:02.522 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:35:02.522 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/10 08:35:02.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7795 bytes) 
24/04/10 08:35:02.531 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
24/04/10 08:35:02.600 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Getting 1 (204.4 KiB) non-empty blocks including 1 (204.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/10 08:35:02.604 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
24/04/10 08:35:02.645 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO CodeGenerator: Code generated in 34.7897 ms
24/04/10 08:35:02.740 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 195879 bytes result sent to driver
24/04/10 08:35:02.742 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 215 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:35:02.743 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.233 s
24/04/10 08:35:02.744 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:35:02.744 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/10 08:35:02.744 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/10 08:35:02.744 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.251902 s
24/04/10 08:35:02.765 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.3585 ms
24/04/10 08:42:47.946 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/conf/hive-site.xml
24/04/10 08:42:48.329 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.1
24/04/10 08:42:48.329 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 10, 10.0, amd64
24/04/10 08:42:48.330 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_401
24/04/10 08:42:48.366 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/10 08:42:48.559 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/10 08:42:48.624 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:42:48.625 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/10 08:42:48.626 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/10 08:42:48.627 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/10 08:42:48.677 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/10 08:42:48.709 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/10 08:42:48.710 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/10 08:42:48.823 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: ricecakes
24/04/10 08:42:48.824 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: ricecakes
24/04/10 08:42:48.826 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/10 08:42:48.826 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/10 08:42:48.826 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ricecakes; groups with view permissions: EMPTY; users with modify permissions: ricecakes; groups with modify permissions: EMPTY
24/04/10 08:42:49.023 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 62555.
24/04/10 08:42:49.083 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/10 08:42:49.158 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/10 08:42:49.208 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/10 08:42:49.210 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/10 08:42:49.215 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/10 08:42:49.256 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\blockmgr-5b22b85a-8ad4-45d1-9485-614ab684462c
24/04/10 08:42:49.275 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/10 08:42:49.313 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/10 08:42:49.318 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/10 08:42:49.575 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
24/04/10 08:42:49.706 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/10 08:42:49.792 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/ricecakes/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:62555/jars/sparklyr-master-2.12.jar with timestamp 1712752968318
24/04/10 08:42:49.923 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
24/04/10 08:42:49.923 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 10, 10.0, amd64
24/04/10 08:42:49.923 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_401
24/04/10 08:42:49.923 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/10 08:42:49.940 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@35422821 for default.
24/04/10 08:42:49.962 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:62555/jars/sparklyr-master-2.12.jar with timestamp 1712752968318
24/04/10 08:42:50.026 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62555 after 26 ms (0 ms spent in bootstraps)
24/04/10 08:42:50.026 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:62555/jars/sparklyr-master-2.12.jar to C:\Users\ricecakes\AppData\Local\spark\spark-3.5.1-bin-hadoop3\tmp\local\spark-f40625e7-bb9a-4a8b-b10e-dab860ff8f37\userFiles-58da870a-1659-48d5-8862-72cdfdd8f3d8\fetchFileTemp2728167263782846624.tmp
24/04/10 08:42:50.155 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/local/spark-f40625e7-bb9a-4a8b-b10e-dab860ff8f37/userFiles-58da870a-1659-48d5-8862-72cdfdd8f3d8/sparklyr-master-2.12.jar to class loader default
24/04/10 08:42:50.175 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62583.
24/04/10 08:42:50.175 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:62583
24/04/10 08:42:50.175 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/10 08:42:50.195 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62583, None)
24/04/10 08:42:50.200 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62583 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 62583, None)
24/04/10 08:42:50.205 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62583, None)
24/04/10 08:42:50.208 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62583, None)
24/04/10 08:42:50.673 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/10 08:42:50.691 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive'.
24/04/10 08:42:56.542 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/10 08:42:56.991 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/ricecakes/AppData/Local/spark/spark-3.5.1-bin-hadoop3/tmp/hive
24/04/10 08:42:57.230 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/10 08:42:57.230 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/10 08:42:57.230 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/10 08:42:57.315 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/10 08:42:57.540 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/10 08:42:57.540 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/10 08:42:59.430 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/10 08:43:02.169 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/10 08:43:02.185 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/10 08:43:02.295 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/10 08:43:02.296 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.86.223
24/04/10 08:43:02.336 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/10 08:43:02.586 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/10 08:43:02.586 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/10 08:43:02.669 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/10 08:43:02.857 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:43:02.860 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:43:02.883 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/10 08:43:02.883 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/10 08:43:02.884 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/10 08:43:02.886 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:43:02.886 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:43:02.886 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/10 08:43:02.886 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_database: default	
24/04/10 08:43:02.886 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/10 08:43:02.886 nioEventLoopGroup-2-2 INFO audit: ugi=ricecakes	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/10 08:43:04.271 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 386.1114 ms
24/04/10 08:43:04.486 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:43:04.489 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.009491 s
24/04/10 08:43:13.430 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 391.9419 ms
24/04/10 08:43:13.460 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:43:13.480 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:43:13.481 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/10 08:43:13.481 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:43:13.483 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:43:13.488 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
24/04/10 08:43:13.585 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.1 KiB, free 912.3 MiB)
24/04/10 08:43:13.651 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
24/04/10 08:43:13.666 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62583 (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:43:13.672 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
24/04/10 08:43:13.693 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:43:13.695 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/10 08:43:13.794 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8003 bytes) 
24/04/10 08:43:13.819 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/10 08:43:14.299 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 23.2191 ms
24/04/10 08:43:14.351 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1499 bytes result sent to driver
24/04/10 08:43:14.366 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 610 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:43:14.366 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/10 08:43:14.384 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.869 s
24/04/10 08:43:14.390 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:43:14.390 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/10 08:43:14.391 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.930803 s
24/04/10 08:43:14.483 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 50.415 ms
24/04/10 08:43:15.006 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:43:15.006 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:43:15.006 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/10 08:43:15.006 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:43:15.006 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:43:15.006 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
24/04/10 08:43:15.017 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.1 KiB, free 912.3 MiB)
24/04/10 08:43:15.020 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
24/04/10 08:43:15.021 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62583 (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:43:15.021 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
24/04/10 08:43:15.022 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:43:15.023 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/10 08:43:15.025 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8003 bytes) 
24/04/10 08:43:15.026 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/10 08:43:15.036 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1370 bytes result sent to driver
24/04/10 08:43:15.038 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 14 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:43:15.039 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/10 08:43:15.040 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.034 s
24/04/10 08:43:15.040 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:43:15.040 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/10 08:43:15.041 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.030585 s
24/04/10 08:43:15.789 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 36.588 ms
24/04/10 08:43:15.838 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:43:15.839 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:43:15.840 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/10 08:43:15.840 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:43:15.841 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:43:15.842 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/10 08:43:15.842 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.2 KiB, free 912.3 MiB)
24/04/10 08:43:15.842 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 912.3 MiB)
24/04/10 08:43:15.850 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62583 (size: 4.7 KiB, free: 912.3 MiB)
24/04/10 08:43:15.851 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
24/04/10 08:43:15.852 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:43:15.852 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/10 08:43:16.465 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (60001 KiB). The maximum recommended task size is 1000 KiB.
24/04/10 08:43:16.465 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 61441898 bytes) 
24/04/10 08:43:16.465 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/10 08:43:16.602 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:62583 in memory (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:43:16.624 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:62583 in memory (size: 3.8 KiB, free: 912.3 MiB)
24/04/10 08:43:16.864 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 34.7913 ms
24/04/10 08:43:17.197 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 939278 bytes result sent to driver
24/04/10 08:43:17.201 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1348 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:43:17.202 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1.360 s
24/04/10 08:43:17.203 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:43:17.203 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/10 08:43:17.204 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/10 08:43:17.204 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1.365354 s
24/04/10 08:43:17.314 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 33.9576 ms
24/04/10 08:44:28.281 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 117.8126 ms
24/04/10 08:44:28.437 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 12 (collect at utils.scala:26) as input to shuffle 0
24/04/10 08:44:28.444 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:44:28.445 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collect at utils.scala:26)
24/04/10 08:44:28.446 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/10 08:44:28.448 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:44:28.450 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[12] at collect at utils.scala:26), which has no missing parents
24/04/10 08:44:28.471 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 50.9 KiB, free 912.2 MiB)
24/04/10 08:44:28.500 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 912.2 MiB)
24/04/10 08:44:28.501 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62583 (size: 21.0 KiB, free: 912.3 MiB)
24/04/10 08:44:28.501 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
24/04/10 08:44:28.504 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[12] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:44:28.504 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/10 08:44:28.780 dispatcher-event-loop-2 WARN TaskSetManager: Stage 3 contains a task of very large size (60001 KiB). The maximum recommended task size is 1000 KiB.
24/04/10 08:44:28.781 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 61441887 bytes) 
24/04/10 08:44:28.782 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/10 08:44:29.025 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 81.9193 ms
24/04/10 08:44:29.071 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 21.5682 ms
24/04/10 08:44:29.113 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 12.9027 ms
24/04/10 08:44:29.146 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 12.7731 ms
24/04/10 08:44:29.160 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 11.9545 ms
24/04/10 08:44:29.459 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2302 bytes result sent to driver
24/04/10 08:44:29.459 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 954 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:44:29.459 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/10 08:44:29.477 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:26) finished in 1.022 s
24/04/10 08:44:29.478 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/10 08:44:29.479 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/10 08:44:29.480 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/10 08:44:29.480 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/10 08:44:29.519 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
24/04/10 08:44:29.542 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
24/04/10 08:44:29.610 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 37.1681 ms
24/04/10 08:44:29.669 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/10 08:44:29.671 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/10 08:44:29.672 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/10 08:44:29.672 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
24/04/10 08:44:29.672 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/10 08:44:29.674 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
24/04/10 08:44:29.692 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 54.3 KiB, free 912.2 MiB)
24/04/10 08:44:29.692 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 912.1 MiB)
24/04/10 08:44:29.692 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62583 (size: 22.6 KiB, free: 912.3 MiB)
24/04/10 08:44:29.692 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
24/04/10 08:44:29.692 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/10 08:44:29.692 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/10 08:44:29.713 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7795 bytes) 
24/04/10 08:44:29.713 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
24/04/10 08:44:29.783 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Getting 1 (204.4 KiB) non-empty blocks including 1 (204.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/10 08:44:29.795 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 33 ms
24/04/10 08:44:29.827 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO CodeGenerator: Code generated in 39.077 ms
24/04/10 08:44:29.965 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 195836 bytes result sent to driver
24/04/10 08:44:29.968 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 260 ms on 127.0.0.1 (executor driver) (1/1)
24/04/10 08:44:29.968 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/10 08:44:29.970 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.293 s
24/04/10 08:44:29.971 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/10 08:44:29.971 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/10 08:44:29.971 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.301722 s
24/04/10 08:44:29.992 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.7772 ms
24/04/10 08:44:42.656 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
